{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyME8EGsgENK1xBZiF1kR/9Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<div style=\"width:100vw;margin-left:calc(50% - 50vw);\"><table width=\"100%\" cellspacing=\"10\" cellpadding=\"14\" bgcolor=\"#f9fafb\" style=\"border:1px solid #d1d5db;border-radius:12px;\"><tr><td width=\"33%\" align=\"center\" valign=\"middle\" bgcolor=\"#ffffff\" style=\"border-radius:10px;\"><a href=\"https://github.com/rikkirch/Computer_Pattern_and_Vision_Recognition/blob/main/Assignment/Assignment_1/Rikesh_Budhathoki_A1.ipynb\" target=\"_parent\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" width=\"28\"></a><br><span style=\"color:#000000;font-family:Georgia,serif;font-size:20px;font-weight:700;\">View on GitHub</span></td><td width=\"33%\" align=\"center\" valign=\"middle\" bgcolor=\"#ffffff\" style=\"border-radius:10px;\"><a href=\"https://nbviewer.org/github/rikkirch/Computer_Pattern_and_Vision_Recognition/blob/main/Assignment/Assignment_1/Rikesh_Budhathoki_A1.ipynb\" target=\"_parent\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/Jupyter_logo.svg/883px-Jupyter_logo.svg.png\" width=\"28\"></a><br><span style=\"color:#000000;font-family:Georgia,serif;font-size:20px;font-weight:700;\">Open in nbviewer</span></td><td width=\"33%\" align=\"center\" valign=\"middle\" bgcolor=\"#ffffff\" style=\"border-radius:10px;\"><a href=\"https://colab.research.google.com/github/rikkirch/Computer_Pattern_and_Vision_Recognition/blob/main/Assignment/Assignment_1/Rikesh_Budhathoki_A1.ipynb\" target=\"_parent\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" width=\"28\"></a><br><span style=\"color:#000000;font-family:Georgia,serif;font-size:20px;font-weight:700;\">Run in Colab</span></td></tr></table></div>\n"],"metadata":{"id":"jD6YKGBGLQmz"}},{"cell_type":"markdown","source":["### **Step 0: Mount Google Drive**\n","\n","In Google Colab, the runtime environment is temporary, meaning any files uploaded directly to Colab are lost when the session ends. Since our calibration images are stored permanently in **Google Drive**, we need to mount Drive into Colab so that the notebook can access those files.\n","\n","By mounting Google Drive:\n","\n","* We can **read calibration images directly from Drive**\n","* We avoid re-uploading images every time the runtime restarts\n","* Our data remains **persistent and organized** across sessions\n","\n","Once mounted, Google Drive behaves like a normal directory in the Colab file system, allowing us to load images using standard file paths.\n","\n","This step must be done **before** accessing any images stored in Google Drive.\n","\n","---"],"metadata":{"id":"MspfLxj6Cm9i"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"ih-am6MAHym5","executionInfo":{"status":"ok","timestamp":1769544352509,"user_tz":360,"elapsed":738,"user":{"displayName":"Rikesh Budhathoki","userId":"13443346662502450491"}},"outputId":"1f308d36-c71b-4f8b-9da3-6fe6efbf8dc5","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["## **Step 1: Load Calibration Images from Google Drive**\n","\n","In this step, the calibration images stored in Google Drive are accessed and prepared for processing.\n","\n","After mounting Google Drive, the images are loaded from the specified directory using file-pattern matching. This allows the notebook to automatically collect all calibration images without manually listing each filename.\n","\n","The main goals of this step are:\n","\n","* to **verify that Google Drive is correctly mounted**\n","* to **confirm that all calibration images are accessible**\n","* to **ensure the correct number of images is loaded before proceeding**\n","\n","This step does **not** perform any computer vision operations yet.\n","It serves as a validation step to confirm that the dataset is correctly located and ready for further processing.\n","\n","If the images cannot be loaded correctly at this stage, subsequent steps such as corner detection and camera calibration will fail.\n","\n","---\n","\n","### **Outcome of this step**\n","\n","* A list of calibration image file paths is successfully created\n","* The total number of images is confirmed\n","* The dataset is ready for grayscale conversion and chessboard corner detection\n","\n","---\n","\n","### **Why this step is important**\n","\n","Camera calibration relies on multiple images taken from different viewpoints. Ensuring that all calibration images are properly loaded at the beginning helps avoid silent errors later in the pipeline and guarantees reproducibility of the results.\n","\n","---"],"metadata":{"id":"FOPfCDn0N10I"}},{"cell_type":"code","source":["import cv2\n","import matplotlib.pyplot as plt\n","import os\n","import numpy as np\n","import glob\n","from tqdm import tqdm"],"metadata":{"id":"zMFusfUlEGG_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img_paths = sorted(glob.glob(\"/content/drive/MyDrive/CSC_422/Assignment_1/Datasets/*.jpeg\"))\n","num_img = len(img_paths)\n","print(f\"Number of images: {num_img}\")\n","for path in img_paths:\n","    print(path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"19L7rVnnNufI","executionInfo":{"status":"ok","timestamp":1769547547956,"user_tz":360,"elapsed":1005,"user":{"displayName":"Rikesh Budhathoki","userId":"13443346662502450491"}},"outputId":"2cb2eb14-1a00-4b7e-f9d3-c7e8ff48f20e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of images: 12\n","/content/drive/MyDrive/CSC_422/Assignment_1/Datasets/IMG_1.jpeg\n","/content/drive/MyDrive/CSC_422/Assignment_1/Datasets/IMG_10.jpeg\n","/content/drive/MyDrive/CSC_422/Assignment_1/Datasets/IMG_11.jpeg\n","/content/drive/MyDrive/CSC_422/Assignment_1/Datasets/IMG_12.jpeg\n","/content/drive/MyDrive/CSC_422/Assignment_1/Datasets/IMG_2.jpeg\n","/content/drive/MyDrive/CSC_422/Assignment_1/Datasets/IMG_3.jpeg\n","/content/drive/MyDrive/CSC_422/Assignment_1/Datasets/IMG_4.jpeg\n","/content/drive/MyDrive/CSC_422/Assignment_1/Datasets/IMG_5.jpeg\n","/content/drive/MyDrive/CSC_422/Assignment_1/Datasets/IMG_6.jpeg\n","/content/drive/MyDrive/CSC_422/Assignment_1/Datasets/IMG_7.jpeg\n","/content/drive/MyDrive/CSC_422/Assignment_1/Datasets/IMG_8.jpeg\n","/content/drive/MyDrive/CSC_422/Assignment_1/Datasets/IMG_9.jpeg\n"]}]},{"cell_type":"markdown","source":["## **Step 3: Detect Chessboard Inner Corners in Each Image**\n","\n","In this step, we detect the **inner corner points** of the chessboard pattern in each calibration image. These inner corners correspond to the intersection points between adjacent black and white squares and are consistent across all images.\n","\n","The purpose of this step is to establish a correspondence between:\n","\n","* **Known 3D points in the real world** (defined by the chessboard geometry), and\n","* **Observed 2D points in the image** (pixel locations of the detected corners).\n","\n","For each image, the chessboard is first converted to grayscale to simplify processing. Then, OpenCV’s chessboard corner detection algorithm is applied to locate the inner corners. If the expected number of corners is successfully detected, their pixel coordinates are stored and optionally visualized on the image for verification.\n","\n","Accurate corner detection is crucial for reliable camera calibration. Images with motion blur, poor lighting, extreme viewing angles, or partial occlusion may fail to produce correct corner detections and should be excluded.\n","\n","**Outcome of this step:**\n","\n","* A list of 2D image points (pixel coordinates of inner corners) for each valid image\n","* A visual confirmation that the detected corners align correctly with the chessboard pattern\n","\n","These detected image points are later used together with the known 3D world coordinates to compute the camera’s intrinsic and distortion parameters.\n","\n","---"],"metadata":{"id":"b08mCoAHQiVv"}},{"cell_type":"code","source":["# Define inner-corner pattern size, 9 - columns, 6 - rows\n","# I have 10 x 7 chessboard so that makes 9 x 6 inner corners\n","pattern_size = (9,6)\n"],"metadata":{"id":"PbRT-yP_Q30-"},"execution_count":null,"outputs":[]}]}